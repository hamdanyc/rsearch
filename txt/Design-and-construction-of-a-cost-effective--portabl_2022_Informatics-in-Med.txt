Informatics in Medicine Unlocked 30  2022  100927 Available online 31 March 2022 2352 9148   2022 The Authors. Published by Elsevier Ltd. This is an open access article under the CC BY NC ND license   http   creativecommons.org licenses by  nc nd 4.0   . Contents lists available at ScienceDirect Informatics in Medicine Unlocked journal homepage  www.elsevier.com locate imu Design and construction of a cost effective  portable sign language to speech translator Muhammed Rashaad Cassim  Jason Parry   Adam Pantanowitz  David M. Rubin Biomedical Engineering Research Group  School of Electrical and Information Engineering  University of the Witwatersrand  Johannesburg Private Bag 3  2050  Johannesburg  South Africa A R T I C L E I N F O Keywords  American Sign Language Gesture detection Gesture classification Machine learningA B S T R A C T This paper presents the design and construction of a cost effective  portable sign language to speech translator. The system is designed to work with American Sign Language fingerspelling  which facilitates translation in any Latin alphabet based language  and aims to translate a pangram into speech. The system consists of three subsystems  namely  gesture detection  gesture classification  and text to speech subsystems and relies on a power bank for its power supply. The gesture detection subsystem makes use of five flex sensors  each placed on the finger of a glove  as well as a three axis accelerometer. Gesture classification is achieved through a supervised machine learning approach   five different algorithms are compared to determine the best configuration for this system. Overall  a support vector machine with a radial basis function kernel and a penalty parameter of 10.0 performs best in the context of this investigation. Using the best case sensor configuration  and the best performing machine learning classifier  the system achieves a practical repeatability of 85.51 . Text to speech translation of the classified gestures is performed using the eSpeak engine. Overall  the system costs under  35 which is lower when compared to similar systems investigated  that cost at least  100. The final system meets the initial goals of sign language to speech translation  portability and cost effectiveness. 1. Introduction The World Health Organisation estimates that approximately 466 million people have disabling hearing loss globally  all of whom require a means of communication   1 . The primary means of communication for these people is sign language   2 . There are many variants of sign language  which can be broadly characterised as either fingerspelling or signed languages   2 . While signed languages focus on signing more quickly  they suffer from a number of disadvantages including  differing between locations even within the same country  a tendency to represent implied language as they rely on more than just hand position  and the assumption that the user has two hands with which to sign   2 . This would require a fairly complex system to interpret full body gestures and cues. The advantages of fingerspelling include facilitating communication in any language  provided it is based on a Latin alphabet and provided the person knows the variant of fingerspelling  of which there are two   as well as inclusion of people with disabilities since the ASL fingerspelling system can be used by people with dexterity in one hand   2 . Additionally  a system based on fingerspelling would be less complex as it only relies on the degree of finger flexion and hand  Corresponding author. E mail addresses  1046955 students.wits.ac.za  J. Parry   david.rubin wits.ac.za  D.M. Rubin .orientation of one hand   2 . As such  ASL fingerspelling is selected for the purposes of this investigation  with the addition of a character to represent a space to indicate to the system that the word being signed is complete. This paper presents the design and implementation of a cost  effective  portable sign language to speech translator. Initially  a de  scription of the system is provided comprising relevant success criteria  assumptions and constraints. This is followed by a review of existing solutions  as well as a design of the overall system  and a detailed explanation of the materials and methods used in this investigation. The materials and methods are split into gesture detection and gesture classification techniques. These techniques are tested under appropriate categories  and the results are used to evaluate the system in terms of the overall success criteria and to provide suggestions for future work and improvements. The final goal of the system is to allow the user to finger spell sen  tences containing every letter in the English alphabet  pangrams  and have their gestures translated into speech in order to communicate with hearing abled people who may not know sign language. To facilitate access by hearing impaired people in low income groups  the solution https   doi.org 10.1016 j.imu.2022.100927 Received 21 November 2021  Received in revised form 21 March 2022  Accepted 21 March 2022

Informatics in Medicine Unlocked 30  2022  100927 2M.R. Cassim et al. Fig. 1. A block diagram of the overall system. should be cost effective. In addition  the system should be sufficiently portable to facilitate users  access to its functionality when travelling. The overall success or failure of the system will be measured against the above goals. Success of the gesture detection subsystem is de  termined by its ability to record unique data from different gestures and relay it to the classification subsystem. For full functionality  the classification subsystem is required to use this data to classify gestures as letters and the text to speech subsystem should output the classified and concatenated letters as speech. For the purpose of this investigation  it is assumed that  the user s language is based on the English alphabet  users will sign right handed  the system will not be used in wet environments  and the user knows the fingerspelling variant of American Sign Language  ASL . System constraints include user safety considerations  the ability of the soft  ware to run on a portable microcontroller and adherence to a valid  accepted  sign language alphabet. Additionally  the system should provide an improvement on existing gesture detection research in the context of sign language translation. Various gesture detection techniques  which provide sensor output based on the gesture performed  are currently in existence   3 5 . The main technique used for gesture detection is image based where the image is segmented and processed in preparation for classification   3 . Contact sensors are also used which provide an indication of hand position and finger flexion  generally through some combination of electromyographical  flex and accelerometer sensors   4 . Similarly  re  search focusing on a glove to convert sign language to speech indicates that the glove may cost approximately  100  leading to the desire for a more cost effective device to be created   5 . Lastly  existing solutions have been shown to exhibit accuracy of between 75  and 92    3 4 . As such  based on the existing research done  the solution should be as cheap as possible  while retaining similar accuracy and sufficient portability. Gesture classification is the translation and interpretation of sensor data into labels which represent the gestures performed   6 . This sensor data may come from any of the aforementioned gesture detection techniques. The output of gesture classification in the case of ASL fingerspelling is the letter which has been signed. Whilst existing ASL fingerspelling gesture detection solutions may provide sufficient accu  racy  they face issues of high cost and lack of portability   specifically those solutions which are image based   5 . A variety of classification techniques exist to translate sensor input into gesture labels. When the detection system is image based  users are generally required to wear coloured gloves to enable classification through hidden Markov models or machine learning   3 . Classification of gesture data obtained through physical sensors also tends to be achieved using machine learning classification algorithms   4 . Existing research into gesture classification algorithms indicates that there is no universally best learning algorithm   7 . However  certain algorithms tend to perform better in different circumstances. In the case of a binary classification problem  it is found that decision tree  neural network  random forest and support vector machine  SVM  algorithms perform best  overall   8 . Multiclass classification problems   such as classifying ASL fingerspelling gestures  26 letters    are a naturalTable 1 Summary of the materials used in the final system. System Aspect Components Sensing componentsMPU 6050 Accelerometer IC Velostat Silver woven conductive fabric Cotton thread Glove Srixon leather glove Arm band Cotton sweat band ADC Chip MCP3008 I P ADC IC Raspberry Pi Pi Zero MiscellaneousResistors and Capacitors Cotton Fabric Power bank Generic power bank extension of binary classification problems. As such  similar algorithms are expected to perform well in multiclass classification problems   7 . Thus  the aforementioned algorithms are used in this investigation. A similar investigation involved the use of a data glove in the design of a work flow which translates different dynamically captured signs   9 . The research in paper   9  indicates that a glove is an appropriate method for gesture detection  over existing solutions  and  specifically  identifies the most suitable classifier for this type of wear  able system to be a multi layer perceptron neural network   9 . This further reinforces the use of a neural network as part of this inves  tigation. However  this research focused only on a small subset of fingerspelling  the Australian variant  and cost upwards of  100 which leaves room for potential reduction   9 . Text to speech  TTS  translation  also known as speech synthesis  refers to the conversion of written symbols into an audible  understand  able format   10 . Two main approaches to TTS translation currently exist  namely  manual encoding of words and the use of phonemes. The manual approach involves storing a sound byte for each word that is to be translated. The text words are then mapped to these sound bytes which are played when the word to which they are mapped is to be synthesised. In a phoneme based approach  the system translates text into   symbolic linguistic representations    letter combinations  which are then converted into speech   11 . 2. Material and methods The overall system is divided into three subsystems. Data is obtained through the gesture detection subsystem  which flows into the gesture classification subsystem and becomes an output from the TTS subsys  tem. This is shown in Fig. 1 and a summary of the materials used is described in Table 1. Each subsystem is discussed in detail below. 2.1. Gesture detection 2.1.1. Overall hardware considerations The overall hardware system design is largely governed by two fac  tors  it should be as cost effective as is feasible and portable. Due to this 

Informatics in Medicine Unlocked 30  2022  100927 3M.R. Cassim et al. Fig. 2. A photograph of the final system s construction. several design decisions are made that dictate the means through which the system quantitatively measures different sign language gestures. In the context of a cost effective and portable solution  the use of a camera to detect hand position is rejected due to the cost and practicality of using a camera in different lighting conditions and with differing backgrounds   12 . Therefore  a decision is made to use a glove to detect gestures using two sets of measurements. The first set is used to determine how flexed each finger is. The second set is used to determine the orientation of the hand. Portability of the solution necessitates that the circuitry be fastened to the glove. As a result  the glove should not create static which might damage the circuitry. Thus  a synthetic leather golf glove is chosen for its desirable physical properties and cost effectiveness as presented in Fig. 2. The algorithm used for gesture detection runs constantly  while the system is on  and samples data at a frequency of 100 Hz. When the glove is still  the last ten sampled data points are fed into the gesture classification subsystem which returns a set of letters  representing the classified gestures. For accuracy  the mode of the set is obtained and used to build up a word. When a space is identified  the completed word is passed to the TTS subsystem. 2.1.2. Sensing finger flexion The sensor used to detect finger flexion must be flexible enough not to impede finger movement and needs to be of a similar size to the finger in order to fit on the glove. The sensor must have adequate pre  cision  repeatable measurements  and sensitivity to detect the different finger flexion states of ASL fingerspelling. Initially  the FS7954 flex sensor is considered. However  each sensor is 0.05588 m  2.2     long and would therefore not cover the entire length of each finger   13 . Each sensor s dimensions would then  there  fore  not be optimised for the finger it is measuring. This might result in a gesture s measurements being less distinguishable. A decision is made to fabricate a sensor for the glove that can be optimised for each finger and may be more cost effective than the FS7954 sensor. Fig. 3 shows a diagram of the fabricated sensor. The sensor operates as a force dependent piezoresistive sensor  where resistance decreases with an increase in applied force   14 . Conductive fabric is used to allow the sensor to remain flexible and to form the conductive layer for the two connections to the sensor. The two outermost pieces of conductive fabric ensure constant and consistent contact with the wire on each side of the sensor. Velostat is placed in the middle of the sensor to create the sensor s piezoresistive properties. It is a material that has been doped with carbon black molecules  which are conductive   14 . When an increased force is applied to the sensor  these molecules move closer together and allow for a lower resistance to conduction   14 15 . Fig. 3. The fabricated sensor design. 2.1.3. Sensing hand orientation Due to certain gestures involving changes in hand orientation  a sensor is required that allows the hand s orientation to be deter  mined while being small enough to be attached to the glove without noticeably impeding movement. The MPU 6050 motion tracking sensor integrated circuit  IC  is used in the final system   16 . The IC provides access to data from a gyroscope as well as an accelerometer   16 . This is beneficial as both sensors might provide unique data for gesture detection from one compact IC. However  it is decided to use the IC s accelerometer data only. The reasons for this are further discussed in Section 3.2. 2.1.4. Compound sensing package In addition to the above sensing strategies  a commercial sensing package is included in the investigation in the form of the Thalmic labs MYO  electro myographical  EMG  compound sensor. This package includes multiple individual sensors which may be combined to deter  mine a variety of gesture related parameters. The first set of sensors consists of eight individual EMG sensors placed around the forearm. This could allow the hand s position to be determined based on the fore  arm flexor muscles which control many aspects of the hand s motion. The remaining two sensor sets consist of a three axis accelerometer  and a three axis gyroscope. The Myo compound sensor is included in the investigation due to the addition of sensors with different operating principles  specifically  the measurement of EMG data  which has the potential to provide a better representation of gestures than other sensing methods. This data may also be beneficial in terms of providing higher dimensionality which may lead to easier differentiation between gestures and  thus  more accurate classification of gestures. This said  the cost of the device is  200 which may be prohibitively expensive when considering the overall goal of cost effectiveness. 2.1.5. Additional hardware considerations The system requires a microprocessor to execute the gesture clas  sification algorithm and read in all sensor data. This microprocessor is  additionally  required to output speech once a word has been signed. Due to availability and cost  the two microprocessors under consideration are an ATMEGA 328 and a Raspberry Pi Zero W. Despite its higher cost  the Raspberry Pi is chosen since it allows more reliable access to non volatile memory  has additional computational power  beneficial when using machine learning models   and has access to a more suitable TTS engine. The Raspberry Pi is required to sample 5 ADC values to obtain all flex sensor readings. Thus  it is decided that the MCP3008 ADC IC will be used  which facilitates conversion of a maximum of 8 analogue channels simultaneously   17 . The sampling rate used is 100 Hz. This is sufficient for the applica  tion as the gesture classification algorithm developed is only concerned with periods where the glove is still and  thus  does not require the more dynamic regions of the data. A lower sampling rate limits the number of times the Pi needs to write to memory and reduces the associated computational cost without hindering the glove s usability.

Informatics in Medicine Unlocked 30  2022  100927 4M.R. Cassim et al. A power bank with a 5 V output is used as the system power supply. Due to the selected power bank s capacity of 6000 mAh and the average current draw of a Raspberry Pi Zero being between 120 mA and 170 mA  it can potentially supply the circuit with power for between 35 and 50 h  thus avoiding the need for frequent charging  18 . 2.1.6. Experimental analysis In order to evaluate the effectiveness of the hardware s ability to de  tect different gestures  a quantitative analysis is carried out. Attaining absolute consistency of these values is not practically feasible due to the potential variation that might exist when signing the same gesture. To test the linearity of the constructed sensor  the index finger s fabricated flex sensor and store bought sensor are bent to differing angles and the voltage over each sensor is measured. The experimental setup is the same as that used for each sensor on the final glove. Four sets of data are taken  each recording consisting of 10 measurements at each angle over 0.1 s  while the sensor is held in place. The mean of these values is taken to better estimate the true value. This testing methodology is adopted in an attempt to limit the measurement error of the test. Eq.  1  gives the ideal linear relationship between the flexion angle of the sensor and the voltage over it. This relationship is defined over the region investigated.          1  Where   is the sensitivity coefficient of the sensor  is the angle at which the sensor is flexed  is the voltage over the flex sensor  V   is the zero bias of the sensor Additionally  this linear relationship allows the sensitivity and non  linearity of the fabricated sensor to be evaluated. These can then be compared to those of the store bought sensor  FS7954 . Equations for the sensitivity and non linearity can be seen in Eqs.  2  and  3 .                    2                              max        100  3  Where  Dmax is the maximum deviation of the measured sensor data from the ideal sensor data Range is the range of values present in the measured sensor data 2.1.7. Practical analysis To determine the feature set used in gesture classification  a practi  cal analysis of the sensor s statistical independence is carried out. The data for this practical analysis is taken from the training set  the collec  tion of which is discussed  below . The repeatability of the fabricated flex sensors and motion data used to classify gestures is used to decide which sensor combination provides the most consistent and distinct gesture readings. The lower the variance  compared using standard deviation  between individual sensors for different measurements of the same letter  the more consistent the gesture readings. In addition to the above  the temperature dependence of the fab  ricated sensor is evaluated. This is tested by measuring the voltage over the sensor for a specific angle of flexion  at differing ambient temperatures. This allows the effects of temperature on the fabricated sensor to be evaluated within the temperature range of interest. 2.2. Gesture classification Data is recorded and labelled from gestures performed multiple times. This data is then used as training input to a machine learningalgorithm which outputs a model to be used for classification of unseen gesture data. To select an approach which achieves the best results in terms of gesture classification  multiple algorithms are compared under specified categories. 2.2.1. Data collection and partitioning Data is collected by taking measurements over 10 recording ses  sions  each session involving 50 recordings for each gesture  taken after the gesture is performed. Between sessions  the glove is taken off and put back on in differing environmental conditions  at different ambient temperatures  for example . This is done in an attempt to introduce variability into the recordings that better approximates the practical use of the glove. The variability stems from practical non idealities of the measurand. These can be seen through variations in how each letter is signed and how the glove is worn when being removed and put back on between recordings and gestures. The datasets consist of 27 uniformly distributed classes  one for each letter  plus the space gesture . Suitable data partitioning is an important aspect when training machine learning algorithms since it assists with avoiding overfitting and plays a large role in determining how effective the resultant models are. The above datasets are partitioned into one large training set and ten smaller sets for repeatability tests. The larger training set consists of 400 measurements for each ges  ture   40 random measurements from each of the 10 datasets. This set is then split randomly into training and testing subsets using scikit  learn s train test split function with 25  of the data being used for the testing subset. Each of the smaller repeatability sets consists of the remaining 10 readings of each gesture in each of the initial datasets. The pur  pose of these smaller sets is to test the real world accuracy  practical repeatability  of the trained models  on unseen data. 2.2.2. Classification algorithms Five supervised machine learning algorithms are selected for com  parison based on the literature reviewed in Section 1  their perceived suitability to the gesture classification problem  and their ability to run on the system hardware. The classification algorithms selected are  k  nearest neighbours  support vector machine  neural network  decision tree  and random forest. Each algorithm is implemented in Python 3 using the scikit learn library  19 . This library is chosen due to its wide use in scientific research  its industry accepted algorithmic implementations and its ver  satility. This versatility includes both the variety of algorithms provided as well as the number of adjustable parameters in each algorithm   key to the comparisons undertaken in this investigation. The k nearest neighbours classifier works on the principle of iden  tifying datapoints based on their surrounding datapoints. A new data  point is compared to the k  a user selected parameter  points closest to it using the Euclidean distance metric. It is then assigned the most common label in the set of its k nearest neighbours  20 . The main parameters which may be adjusted in a k nearest neighbours classi  fication algorithm are the number of neighbours  k  to be used and the weighting of points  whether closer neighbours have a larger effect or not . This algorithm is implemented using the scikit learn library s KNeighboursClassifier. A support vector machine is a mathematically based machine that can determine a hyperplane which classifies  separates different classes of data  in a manner which is at least close to the optimal solution using the so called  kernel trick   20 . The main parameter which may be adjusted in a support vector classifier is the kernel type  linear  polynomial or radial basis    the shape of lines separating clusters of points. Additionally  adjustments may be made to the penalty co  efficient which determines how strictly the classification boundaries should be set to avoid misclassifications. This algorithm is implemented using the scikit learn library s SVC functionality.

Informatics in Medicine Unlocked 30  2022  100927 5M.R. Cassim et al. A neural network uses multiple layers of perceptrons  artificial neurons  to learn a classification function through an iterative feed  forward and back propagation training phase   20 . There are multiple adjustable parameters  all of which may have a significant effect on both the accuracy and performance of the algorithm. The structure of the network  the number of hidden layers and the number of nodes in each layer  may be adjusted and the learning rate used during the training phase may be altered. This algorithm is implemented using the scikit learn library s MLPClassifier functionality. A decision tree classifier works on the principle of learning thresh  olds for different features in data and classifying points by making decisions based on these thresholds   20 . Decision trees are not gen  erally parameterised  however  two attributes may be adjusted when creating the tree. The loss criterion  Gini impurity or entropy  dictates how the algorithm determines which decisions are good or bad when creating thresholds. The splitting parameter  best or random  specifies whether the best split should be chosen each time a split is made or whether an element of randomness should be introduced in an attempt to create a tree which makes better decisions overall. This algorithm is implemented using scikit learn s DecisionTreeClassifier. A random forest is an ensemble classifier consisting of multiple decision trees which are created using the random splitting technique. Points are then classified by taking the most common output of all trees  voting mechanism . The main parameter which may be changed in the random forest algorithm is the number of decision trees created in the forest. Additionally  as in the decision tree algorithm  either the Gini impurity or entropy loss criterion may be used when constructing the individual decision trees. This algorithm is implemented using scikit learn s RandomForestClassifier. 2.2.3. Classification algorithm parameter tuning and selection The gesture classification algorithms are tested under a variety of categories to find the most well rounded solution which  ultimately  best meets the initial system goals and specifications. First  the cross  validation accuracy of each algorithm is determined when adjusting the various algorithm specific parameters  using the scikit learn library s GridSearchCV functionality . The best configuration  as determined by the grid search  best average cross validation accuracy  considering standard deviation   is then used in a test for practical repeatability on unseen datasets  the collection of which is discussed above . The best case configurations for all of the algorithms are then compared to facilitate selection of the algorithm and configuration which performs best in the context of this system. All algorithms are limited to 10 000 iterations of training  where applicable  and each test is run 5 times for each configuration. The configuration which results in the highest average accuracy  across all tests  is selected. Cross validation accuracy is a measure of how well a trained algo  rithm is able to classify data points within the same set as the training data. Repeatability determines how accurately an algorithm can classify data points from a different dataset to the one it was trained on and is calculated by measuring the average accuracy over a number of different test datasets. This is  perhaps  the most useful measure to determine the ease with which an algorithm can classify unseen data  practical accuracy when signing new gestures   which is one of the ultimate goals of the investigation. Other metrics such as f score and precision are not considered since there is an even class distribution  and they provide little benefit in the context of this investigation which targets practical repeatability. Table 2 indicates the values which are used when tuning the pa  rameters of each algorithm. These algorithms are implemented using an adapter pattern. This ensures a modular system  overall  and enables custom design of the gesture classification component to work with the gesture detection and TTS components. Fig. 4. The voltage angle flexion characteristics of the flex sensors considered. 2.3. Text to speech The text to speech subsystem synthesises classified gestures into a speech signal. When a  space   the additional character  is classified  the eSpeak TTS engine  selected for its quality and phoneme basis  is used to convert the signed word into a speech waveform. This waveform is played over the amplifier speaker circuit. The speaker circuit is used to output the synthesised speech signal. The signal used in this circuit is provided by a GPIO pin of the Raspberry Pi. The circuit consists of two components  a filter and an amplifier. The filter is a second order low pass filter set to 20 kHz  which is the upper frequency range of audible sound   21 . The am  plification stage amplifies the signal with a gain of 20 before it is fed to the speaker. 3. Results The system  as described above  is implemented. To determine the extent to which the system meets its initial specifications  various analyses are performed on each subsystem as well as the overall system. The details of these tests are outlined in Sections 2.1.6   3.2 and 2.2.3 . 3.1. Experimental analysis In order to evaluate the effectiveness of the hardware s ability to de  tect different gestures  a quantitative analysis is carried out. Attaining absolute consistency of these values is not practically feasible due to the potential variation that might exist when signing the same gesture. To obtain Fig. 4  the process described in Section 2.1.6 is followed. Fig. 4 describes the voltage angle flexion characteristic comparison between the fabricated and store bought sensors. Additionally  Eq.  4  provides the ideal linear relationship between the flexion angle of the sensor and the voltage over it. This relationship is defined over the region investigated.     0.03     6  4  Using Eq.  2   the sensitivity of the fabricated and store bought flex sensors is found to be 0.03          and 3.9 10 3            respec  tively. The fabricated sensor  therefore  has a better sensitivity than the store bought sensor and results in more uniquely distinguishable read  ings  provided these are consistent. The fabricated sensor additionally exhibits a maximum non linearity of 9.7   when using Eq.  3 .

Informatics in Medicine Unlocked 30  2022  100927 6M.R. Cassim et al. Table 2 Machine learning algorithm parameters and tuning values considered. Algorithm Parameter Values k nearest neighboursNumber of neighbours1 to 20 Weighting strategy Uniform  distance based support vector machineKernel type linear  polynomial  radial basis Penalty co efficient 0.1  1.0  5.0  10.0  50.0  100.0  1000.0 neural networkStructure  1    2    3    4    5    1  1    1  2    1  3    1  4    1  5    2  1    2  2    2  3    2  4    2  5    5  1    5  2    5  3    5  4    5  5    1  1  1  1  1  1  1  1  1  1  1    5  5  5  5  5    100    500    1000    100  100    100  100  100    100  100  100  100  100  Learning rate 0.001  0.01  0.1  0.2  0.4  0.8  1.0 decision treeLoss criterion gini  entropy Splitting parameter Best  random random forestNumber of estimators1 to 20 Loss criterion gini  entropy Fig. 5. A comparison of the mean relative standard deviation of different sets of sensor data considered when using only the glove. 3.2. Practical analysis The results presented below are based on the data collected as discussed in Section 2.2.1 . The repeatability of the fabricated flex sensors and motion data used to classify gestures is used to decide which sensor combination provides the most consistent and distinct gesture readings. The lower the variance  compared using standard deviation  between individual sensors for different measurements of the same letter  the more consistent the gesture readings. Figs. 5 and 6 summarise the results of an analysis carried out to determine which sensor data should be used in the final system. The combination of flex sensor and accelerometer data is selected to classify gestures. This is due to the accelerometer data introducing three additional dimensions to the data  while having a 0.03 increase in the mean relative standard deviation  when compared to the flex sensors alone. The temperature dependence of the sensor is  additionally  mea  sured to investigate the repeatability of the sensor in varying temper  ature conditions. The results of this can be seen in Fig. 7. The figure shows that  overall  the output of the sensors  for the same angle  increases with ambient temperature. However  digit 4 s temperature drift is 17.35  of its maximum output and could  therefore  cause an incorrect classification  if the glove happened to be used at a temperature which is 7 hotter than that of the test environment. Fig. 6. A comparison of the mean relative standard deviation of different sets of sensor data considered with the Myo data included. 3.3. Gesture classification The data  partitioned as discussed in Section 2.2.1   is used to determine the best combination of the tuning parameters  specified in Table 2. This tuning is done using sci kit learn s GridSearchCV func  tionality  as discussed in 2.2.3 . Thereafter  the best case configuration of each algorithm  based on average accuracy and standard deviation  is used in the practical repeatability tests to find the most well rounded solution which  ultimately  best meets the initial system goals and specifications. From Fig. 8  the SVM exhibits the best performance with an aver  age cross validation accuracy of 99.97  and practical repeatability of 85.51 . Overall the support vector machine yielded the best practical

Informatics in Medicine Unlocked 30  2022  100927 7M.R. Cassim et al. Fig. 7. The temperature drift exhibited by the sensors. Fig. 8. A comparison of cross validation and repeatability results for all algorithms. repeatability using a radial basis function kernel and a relatively low penalty  of 10.0 . As such  the support vector machine is selected for use in the final system in its best configuration. Additionally  the above gesture classification tests are carried out on the Myo sensing package  in combination with the glove. This is done in an attempt to improve upon the practical repeatability when using the glove by itself   adding additional dimensions to the dataset may allow the machine learning algorithms to better classify individual data points. Overall  the random forest algorithm performed best in the context of this sensing setup  however  the practical repeatability achieved is notably worse than that of the SVM algorithm on the glove alone. The glove and Myo combination setup resulted in a practical repeatabil  ity of 72 . This outcome was predicted by the results presented in Section 3.2 where the combination of the flex sensor and glove ac  celerometer readings was determined to be best at uniquely identifying gestures. 3.4. Overall system The final solution was required to be cost effective. Therefore  a comparative hardware cost analysis between a system created using store bought sensors  one using the fabricated sensors  and one using a Myo is performed. The results of this analysis can be seen in Fig. 9. Fig. 9 assumes that labour costs may be neglected when calculating the system s overall cost. Fig. 9 illustrates that the final solution proposed is the most cost effective of the solutions explored. This is due to it costing almost athird of a glove that used store bought sensors and even less when compared to a solution utilising the Myo  while performing the same function. It is additionally more cost effective than solutions that have been proposed previously   5 . The overall system is deemed to be suitably portable both when compared to existing solutions and when considering the fact that it may be carried on one s person easily. This is due to the use of a power bank  with a lifespan of 35 to 50 h between charges  as well as its small form factor. 4. Discussion Based on the results obtained in Section 3  each subsystem is evaluated in terms of the original specifications. The overall system is then evaluated based on the initial goals set out and the engineering trade offs made. Additionally  various social and ethical implications are considered. 4.1. System evaluation The synthesised sensors performed better when compared to store bought sensors in the context of the overall goals of the project. This is due to them having a higher sensitivity and lower non linearity  being cheaper  and exhibiting a relatively low mean standard deviation when practically used. The major drawback of the fabricated flex sensors is the temperature drift exhibited which affected the system s results. It can be further evaluated and accounted for in several ways. In future work  the training dataset could be taken at every temperature in the expected operating temperature range. Alternatively  the glove could incorporate a temperature sensor  which would allow for all readings taken at any temperature to be related to the results taken at a set control temperature. All algorithms performed fairly strongly in the cross validation ac  curacy category  as expected  due to this test being carried out on a single training dataset using an established machine learning library. The decision tree algorithm performed particularly poorly in terms of practical repeatability. The random forest algorithm did not perform as well as may have been expected which could be due to the use of too few decision tree estimators  since the best configuration used the maximum number of estimators tested . The neural network may have achieved an even higher practical repeatability if a better hidden layer structure had been discovered. The k nearest neighbours algorithm performed far better than initially expected  indicating that the high number of dimensions of the input data did not outweigh the effect of balanced  well clustered points. The SVM algorithm performed best in this application with specific focus on the practical repeatability achieved. This may be due to the ability of SVMs to handle classification problems that are higher dimen  sional in nature  due to the  kernel trick  . This is further reinforced by the SVM parameters which led to the highest practical accuracy   a radial basis function kernel and a relatively low penalty   which indicate that the most important aspect of the classification problem was the ability to separate higher dimensional data. It may be possible to improve the repeatability of gesture classification through collection of training datasets from a variety of professional ASL signers. The solution developed improved on that from existing research in two major aspects. When compared to existing solutions  the system can be seen as more cost effective. This is due to existing solutions costing upward of  100  while the current research produced a system costing under  35 in total   9 . Secondly  the system implemented improved on the practical scope of existing research in improving the universal nature of the sign language set used. Existing research utilised the Australian Sign language variant which is less universal than the generic ASL alphabet used in the present study. Additionally  the sensor configuration differed as   9  used ten commercially bought flex sensors

Informatics in Medicine Unlocked 30  2022  100927 8M.R. Cassim et al. Fig. 9. A cost breakdown of the solutions considered.  which may not be tailored to the specific application  and two smart sensors to get the quaternion. The gesture classification results discussed above differ from those found in   9  which indicated that a multi layer perceptron neural network performed best in sign language recognition. This may be due to multiple reasons. One possibility is that the glove used in   9  measured different parameters  a subset of Australian Sign language  as opposed to the entire ASL alphabet  and provided a dataset with dif  ferent dimensionality to the system designed in this paper   meaning the SVM may be the most suitable algorithm for the specific gestures and hand parameters used in this system. Another possible reason is that the neural network in   9  was trained on a public database   more data points may have lead to a better trained model which can more accurately classify gestures. The final possibility is that the investigation performed in this paper did not identify the best neural network structure for the problem  leading to sub optimal performance  or  9  did not identify the most optimal SVM parameters. The speaker circuit is able to output the words to speech  but the audio output is qualitatively deemed not loud enough when played in a loud room with people talking. This is an oversight on the speaker circuit  which is a consequence of prioritising cost and portability. This may be improved in future  but will come at the expense of the aforementioned system goals. Using a Myo added several drawbacks to the system when evaluated against the overall goals. It notably increased the cost of the system  reducing the cost effectiveness of the solution. Secondly  it reduced the system s practical repeatability when classifying gestures   this may be due to the delay introduced by sampling eight EMG sensors over Bluetooth in addition to the other sensors in the system. Lastly  the Myo would add more power consumption limitations to the system  reducing its portability due to a decrease in operating time. Various trade offs have been made during the development of the final system. One alternative design path to make the system adaptable is an Internet of Things approach where the microcontroller offloads new gesture data to a server for training and receives an updated model back. This option is decided against since it requires a data connection  incurring further costs which contradicts the cost effective nature of the project. Overall  the final glove is able to successfully translate an English pangram from sign language to speech with a reasonable level of repeatability   an average of 85  practical accuracy over all letters which is in the upper end of the range presented in existing research  as indicated in Section 1. The only practical drawback with reference to the system is the low volume of the output speech. Additionally  the system meets its goal of portability as a user may wear the glove and use it while travelling with only a power bank attached to supply powerto the system   this power supply is sufficient for up to 50 h of use. Finally  the project meets its goal of cost effectiveness when taking only the component cost  exclusive of labour and other associated costs  into account   the final glove is far cheaper than an alternative using store bought sensors or an alternative means of gesture sensing such as electromyographical sensors or a camera based system. 4.2. Social and ethical implications The system will facilitate communication between people who are deaf and people who do not understand sign language  but are able to hear. Additionally  due to the use of fingerspelling  the system is not tied to a specific language. Therefore  a person from anywhere in the world  that uses a Latin based alphabet  can use the glove to converse with people in their native language  provided there is a supported language pack. An improvement in this respect may be to extend the system to translate other  possibly region specific  ASL dialects. A major social consideration is that the gesture classification system has currently only been trained using data from the creators. This causes a clear bias in the dataset which may result in inaccurate classifi  cation of gestures when used by other people  specifically  people with a different physical hand structure to the creators . One solution to this may be the addition of functionality which allows a user to record their own training data when first using the system. Certain ethical implications are also relevant to this system. The final system is unlikely to cause harm to the wearer which satisfies the safety aspect of the associated ethical responsibilities. The constraint of adhering to a valid sign language alphabet is satisfied  however  to achieve the speech output goal of the project  an additional gesture  which indicates a space between words  is added to the 26 letter ASL manual alphabet. This may necessitate a small learning phase for a person using the glove for the first time. The ethical implications of recording gesture data and classifying based on this was considered prior to conducting the study. As a result of this  an ethics application was submitted and an ethics waiver  ELEN 19P14 W  was issued on 27 May 2019 by the Human Research Ethics Committee  non medical  of the University of the Witwatersrand for the research conducted during the same year. 5. Conclusion Novel research has been conducted which led to the design and construction of a system which translates sign language into speech with the aim of assisting the hearing impaired. It provides an improve  ment on existing research in the categories of cost effectiveness and portability  while maintaining comparable practical repeatability and

Informatics in Medicine Unlocked 30  2022  100927 9M.R. Cassim et al. accuracy. This notably provides a solution which is more applicable in real world scenarios. The system consists of three subsystems  namely  a gesture detection  gesture classification  and TTS subsystem. Each subsystem was designed in line with the initial goals  presented in Section 1 and within the identified constraints. The subsystems were integrated and evaluated using both experimental and practical analy  sis. The final system was deemed to meet the initial goals based on the results obtained from this analysis. Based on the research conducted and the technical considerations identified  future work may include improvements to the system in terms of the output volume  neural network configuration  and sensor temperature sensitivity. Declaration of competing interest The authors declare that they have no known competing finan  cial interests or personal relationships that could have appeared to influence the work reported in this paper. Acknowledgements The authors would like to thank the University of the Witwatersrand and the School of Electrical and Information Engineering for funding and facilitating the project in 2019 which led to the creation of this paper. References  1  WHO. Deafness and hearing loss. 2019  URL https   www.who.int news  room fact sheets detail deafness and hearing loss targetText Over 205 25  20of 20the 20world s will 20have 20disabling 20hearing 20loss.  2  Sandler W  Lillo Martin DC. Sign language and linguistic universals. Cambridge  UK   New York  Cambridge University Press  2006  OCLC  ocm61425229.  3  Bukhari J  Rehman M  Malik S  Kamboh A  Salman A. American sign language translation through sensory glove  SignSpeak. Int J U E Serv Sci Technol 2015 8 1  131 42.  4  Akumalla S. Evaluating appropriateness of EMG and flex sensors for classifying hand gestures. Denton  University of North Texas  2012. 5  O Connor TF  Fach ME  Miller R  Root SE  Mercier PP  Lipomi DJ. The language of glove  Wireless gesture decoder with low power and stretchable hybrid electronics. In  Pisignano D  editor. PLoS One 2017 12 7  e0179766. http    dx.doi.org 10.1371 journal.pone.0179766  URL http   dx.plos.org 10.1371  journal.pone.0179766.  6  Srinivas K  Rajagopal M. Study of hand gesture recognition and classification. Asian J Pharm Clin Res 2017 10 13  25 30.  7  Fernandez Delgado M  Cernadas E  Barro S. Do we need hundreds of classifiers to solve real world classification problems  J Mach Learn Res 2014 15 1  3133 81.  8  Caruana R  Niculescu Mizil A. An empirical comparison of supervised learning algorithms. New York  Cornell University  2006.  9  Pezzuoli F  Corona D  Corradini ML. Recognition and classification of dynamic hand gestures by a wearable data glove. SN Comput Sci 2020 2 1  5. http    dx.doi.org 10.1007 s42979 020 00396 5.  10  Trivedi A  Pant N  Shah P  Sonik S  Agrawal S. Speech to text and text to speech recognition systems a review. IOSR J Comput Eng 2018 20 2  36 43.  11  Hruz M  Campr P  Dikici E  Kindiroglu A  Krnoul Z  Ronzhin A  et al. Automatic fingersign to speech translation system. Multimodal User Interfaces 2011 4 1  61.  12  IST Africa Conference  Cunningham P  Cunningham M  Institute of Electrical and Electronics Engineers  IST Africa Conference  et al. 2018 IST africa week conference 09 11 may 2018  gaborone  botswana. 2018  OCLC  1054400859 URL http   ieeexplore.ieee.org servlet opac punumber 8408414.  13  Spectra Symbol. Flex sensor data sheet. 2014.  14  Giovanelli D  Farella E. Force sensing resistor and evaluation of technology for wearable body pressure sensing. J Sensors 2016 2016 1 13. http   dx.doi. org 10.1155 2016 9391850  URL http   www.hindawi.com journals js 2016  9391850 .  15  Paredes Madrid L  Matute A  Bareno J  Parra Vargas C  Gutierrez Velasquez E. Underlying physics of conductive polymer composites and force sensing re  sistors  FSRs . a study on creep response and dynamic loading. Materials 2017 10 11  1334. http   dx.doi.org 10.3390 ma10111334  URL http   www. mdpi.com 1996 1944 10 11 1334.  16  InvenSense. MPU 6000 and MPU 6050 product specification revision 3.4. 3.4th ed.. 2013.  17  Microchip. MCP3004 3008. 2008.  18  Jeff Geerling. Raspberry pi zero   power consumption comparison. 2015  URL https   www.jeffgeerling.com blogs jeff geerling raspberry pi zero power.  19  Pedregosa F  Varoquaux G  Gramfort A  Michel V  Thirion B  Grisel O  et al. Scikit learn  Machine learning in python. J Mach Learn Res 2011 12 1  2825 30.  20  Pedregosa F  Varoquaux G  Gramfort A  Michel V  Thirion B  Grisel O  et al. Scikit learn  Machine learning in python. J Mach Learn Res 2012 12.  21  International Conference on Mobile Systems  and Services  Applications and ACM SIGMOBILE and Association for Computing Machinery. MobiSys 17  proceedings of the 15th annual international conference on mobile systems  applications  and services   June 19 23  2017  niagara falls  NY  USA. 2017  OCLC  1023034808.

