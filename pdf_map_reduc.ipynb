{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "06c51f87-8245-4f66-ab8f-32d805282085",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import MapReduceDocumentsChain, ReduceDocumentsChain\n",
    "# from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "from langchain.chains.llm import LLMChain\n",
    "# from langchain_core.output_parsers import StrOutputParser \n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_community.document_loaders.pdf import PyPDFLoader\n",
    "from langchain.chat_models import init_chat_model\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642cfec5-7a33-46dd-b42b-25907cfab801",
   "metadata": {},
   "source": [
    "# Load document and chunk it into smaller \"sub documents\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cfddbe13-bfa7-48b7-838f-4ab6c583df25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 9 0 (offset 0)\n",
      "Ignoring wrong pointing object 15 0 (offset 0)\n",
      "Ignoring wrong pointing object 156 0 (offset 0)\n",
      "Ignoring wrong pointing object 158 0 (offset 0)\n",
      "Ignoring wrong pointing object 164 0 (offset 0)\n",
      "Ignoring wrong pointing object 170 0 (offset 0)\n",
      "Ignoring wrong pointing object 172 0 (offset 0)\n",
      "Ignoring wrong pointing object 184 0 (offset 0)\n"
     ]
    }
   ],
   "source": [
    "file_path = \"article/LLMs in medicine_accepted.pdf\"\n",
    "loader = PyPDFLoader(file_path)\n",
    "doc = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "031d325b-b700-4f0b-b9df-f55c39e18df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 46 documents.\n"
     ]
    }
   ],
   "source": [
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=1000, chunk_overlap=0\n",
    ")\n",
    "split_docs = text_splitter.split_documents(doc)\n",
    "print(f\"Generated {len(split_docs)} documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8229203c-3688-45ea-a087-846eb8c1cfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_docs[3:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b16946-3482-4ddd-969d-ea41fceae3e1",
   "metadata": {},
   "source": [
    "# Iniate LLM with Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0b5079-6663-47ad-b156-51e6c3c50532",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "os.environ[\"GROQ_API_KEY\"] = os.environ.get('GROQ_API_KEY')\n",
    "llm = init_chat_model(\"llama3-8b-8192\", model_provider=\"groq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "17c5c956-2479-4e71-9dd9-578f1169a6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    model_name=\"gemma2:2b\",\n",
    "    api_key=\"ollama\",\n",
    "    base_url=\"http://192.168.1.115:11434/v1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7eca9c-07f0-49f1-b798-40a41443aae6",
   "metadata": {},
   "source": [
    "# Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8fd0355c-458c-4531-bb8f-e52d240d7e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_template = \"Write a concise summary of the following: {docs}.\"\n",
    "map_prompt = ChatPromptTemplate([(\"human\", map_template)])\n",
    "# map_chain = map_prompt | llm | StrOutputParser() \n",
    "map_chain = LLMChain(llm=llm, prompt=map_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee346765-7cc0-4acb-86a6-3cdd829eb15a",
   "metadata": {},
   "source": [
    "# Reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d0f25175-f244-491c-b036-d5c6e3fc26bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_template = \"\"\"\n",
    "The following is a set of summaries:\n",
    "{docs}\n",
    "Take these and distill it into a final, consolidated summary\n",
    "of the main themes.\n",
    "\"\"\"\n",
    "reduce_prompt = ChatPromptTemplate([(\"human\", reduce_template)])\n",
    "reduce_chain = LLMChain(llm=llm, prompt=reduce_prompt)\n",
    "# reduce_chain = reduce_prompt | llm | StrOutputParser() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15cee7d-7b0d-46df-8c0a-a526f913d1ba",
   "metadata": {},
   "source": [
    "# Takes a list of documents, combines them into a single string, and passes this to an LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "928c2aea-3c5c-4e29-9013-73b89336891d",
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_documents_chain = StuffDocumentsChain(\n",
    "    llm_chain=reduce_chain, document_variable_name=\"docs\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b417bd-4981-4228-b564-b064b5cce1d9",
   "metadata": {},
   "source": [
    "# Combines and iteratively reduces the mapped documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fefdf10b-95b6-417c-a28d-13d9ea34ab0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_documents_chain = ReduceDocumentsChain(\n",
    "    # This is final chain that is called.\n",
    "    combine_documents_chain=combine_documents_chain,\n",
    "    # If documents exceed context for `StuffDocumentsChain`\n",
    "    collapse_documents_chain=combine_documents_chain,\n",
    "    # The maximum number of tokens to group documents into.\n",
    "    token_max=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c48ab6f-7db3-4ad2-9fb3-719205884242",
   "metadata": {},
   "source": [
    "# Combining documents by mapping a chain over them, then combining results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e3fec88e-aebe-46bc-8af5-8d7a0098428b",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_reduce_chain = MapReduceDocumentsChain(\n",
    "    # Map chain\n",
    "    llm_chain=map_chain,\n",
    "    # Reduce chain\n",
    "    reduce_documents_chain=reduce_documents_chain,\n",
    "    # The variable name in the llm_chain to put the documents in\n",
    "    document_variable_name=\"docs\",\n",
    "    # Return the results of the map steps in the output\n",
    "    return_intermediate_steps=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "baa39e4f-9bd0-40cf-93f6-69bd713befd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:356: UserWarning: Unexpected type for token usage: <class 'NoneType'>\n",
      "  warnings.warn(f\"Unexpected type for token usage: {type(new_usage)}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Large Language Models: Revolutionizing Healthcare & Beyond\n",
      "\n",
      "This text explores the transformative potential of **Large Language Models (LLMs)** in various fields, particularly healthcare.  Here's a breakdown of key takeaways:\n",
      "\n",
      "**1. LLMs are powerful tools:** \n",
      "* They excel at understanding and generating human language, enabling tasks like text completion, generation, and even conversational interaction (e.g., ChatGPT).\n",
      "* Recent advancements allow for impressive performance with minimal fine-tuning, showcasing their adaptability to new tasks.\n",
      "\n",
      "**2. LLMs in healthcare:**\n",
      "* **Applications:** Clinical decision support, education, research are just a few examples of how LLMs are being used in medicine. \n",
      "* **Challenges:**  Current technology requires close supervision due to limitations in model validation and lack of standardized benchmarks.\n",
      "\n",
      "**3. The evolution of LLMs:**\n",
      "* **GPT models:** A series of increasingly powerful models (GPT-2, GPT-3, GPT-4) demonstrate the continuous advancement of LLM capabilities. \n",
      "    *  Smaller models like GPT-2 showed impressive performance despite limited training data and prompt adaptation.\n",
      "    * Larger models like GPT-3 and GPT-4 achieved state-of-the-art results in NLP tasks with massive datasets.\n",
      "    * GPT-4's multimodal capabilities (handling images) mark a significant leap forward.\n",
      "\n",
      "**4. Future directions:** \n",
      "* While LLMs hold immense promise for healthcare research, further development is needed to overcome technological limitations and ensure their successful implementation.  \n",
      "* Focus on improving model validation, standardization, and addressing ethical considerations will be crucial for realizing the full potential of these powerful tools.\n",
      "\n",
      "\n",
      "In essence, LLMs are revolutionizing various fields by enabling sophisticated language understanding and generation. While challenges remain, continued research and development promise to unlock even greater possibilities in healthcare and beyond. \n",
      "\n",
      "CPU times: user 552 ms, sys: 75 ms, total: 627 ms\n",
      "Wall time: 55min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = []\n",
    "result = map_reduce_chain.invoke(split_docs[3:7]) # squares = [x**2 for x in range(10)] | for doc in docs\n",
    "print(result[\"output_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0064ec-464c-4cf0-89c1-1df04b6fb633",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
