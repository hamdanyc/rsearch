{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "06c51f87-8245-4f66-ab8f-32d805282085",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import MapReduceDocumentsChain, ReduceDocumentsChain\n",
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.chat_models import init_chat_model\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c9824d3f-5f1e-4510-9b0d-58c5893bae94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_reduce():\n",
    "\n",
    "    # Init LLM -> groq\n",
    "    load_dotenv()\n",
    "    os.environ[\"GROQ_API_KEY\"] = os.environ.get('GROQ_API_KEY')\n",
    "    llm = init_chat_model(\"llama3-8b-8192\", model_provider=\"groq\")\n",
    "\n",
    "    # Def map template and init prompt\n",
    "    map_template = \"Write a concise summary of the following: {docs}.\"\n",
    "    map_prompt = ChatPromptTemplate([(\"human\", map_template)])\n",
    "    map_chain = LLMChain(llm=llm, prompt=map_prompt)\n",
    "\n",
    "    reduce_template = \"\"\"\n",
    "    The following is a set of summaries:\n",
    "    {docs}\n",
    "    Take these and distill it into a final, consolidated summary\n",
    "    of the main themes.\n",
    "    \"\"\"\n",
    "    reduce_prompt = ChatPromptTemplate([(\"human\", reduce_template)])\n",
    "\n",
    "    reduce_chain = LLMChain(llm=llm, prompt=reduce_prompt)\n",
    "    combine_documents_chain = StuffDocumentsChain(\n",
    "        llm_chain=reduce_chain, document_variable_name=\"docs\"\n",
    "    )   \n",
    "    \n",
    "    # reduce mapped docs | This is final chain that is called.\n",
    "    reduce_documents_chain = ReduceDocumentsChain(\n",
    "        combine_documents_chain=combine_documents_chain, # If documents exceed context for `StuffDocumentsChain`\n",
    "        collapse_documents_chain=combine_documents_chain,\n",
    "        token_max=1000, # The maximum number of tokens to group documents into.\n",
    "    )\n",
    "    \n",
    "    map_reduce_chain = MapReduceDocumentsChain(\n",
    "        # Map chain\n",
    "        llm_chain=map_chain,\n",
    "        # Reduce chain\n",
    "        reduce_documents_chain=reduce_documents_chain,\n",
    "        # The variable name in the llm_chain to put the documents in\n",
    "        document_variable_name=\"docs\",\n",
    "        # Return the results of the map steps in the output\n",
    "        return_intermediate_steps=False,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bbad6ebc-739e-4622-9996-bb1719014b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 9 0 (offset 0)\n",
      "Ignoring wrong pointing object 15 0 (offset 0)\n",
      "Ignoring wrong pointing object 156 0 (offset 0)\n",
      "Ignoring wrong pointing object 158 0 (offset 0)\n",
      "Ignoring wrong pointing object 164 0 (offset 0)\n",
      "Ignoring wrong pointing object 170 0 (offset 0)\n",
      "Ignoring wrong pointing object 172 0 (offset 0)\n",
      "Ignoring wrong pointing object 184 0 (offset 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 46 documents of LLMs in medicine_accepted.pdf.\n",
      "'Summary of LLMs in medicine_accepted.pdf:'\n",
      "('Here is a final, consolidated summary of the main themes:\\n'\n",
      " '\\n'\n",
      " 'Large Language Models (LLMs) have significant potential to transform '\n",
      " 'industries, including healthcare, education, and research, but their '\n",
      " 'development and deployment require careful consideration of challenges and '\n",
      " 'concerns. Key issues include limitations in answering complex questions, '\n",
      " 'lack of evaluation and validation, ethical concerns, and potential '\n",
      " 'inaccuracies. To mitigate these issues, LLMs should be used with expert '\n",
      " 'oversight, updated training data, and transparency measures. Researchers and '\n",
      " 'developers must address data quality and bias issues, develop '\n",
      " 'interpretability measures, implement safeguards for uncertainty and safety, '\n",
      " 'and establish clear regulations and guidelines for LLM use in healthcare '\n",
      " 'settings. Ultimately, the successful development and deployment of LLMs '\n",
      " 'require careful consideration of both the potential benefits and risks, as '\n",
      " 'well as a commitment to addressing the challenges and concerns associated '\n",
      " 'with their use.')\n",
      "Generated 25 documents of s42256-023-00626-4.pdf.\n",
      "'Summary of s42256-023-00626-4.pdf:'\n",
      "('Here is a consolidated summary of the main themes:\\n'\n",
      " '\\n'\n",
      " 'The article discusses the effectiveness of delta-tuning methods for '\n",
      " 'fine-tuning large-scale pre-trained language models (PLMs). Key findings '\n",
      " 'include:\\n'\n",
      " '\\n'\n",
      " '* Delta-tuning methods can improve performance and reduce memory usage, '\n",
      " 'especially when combined with manual templates or larger model scales.\\n'\n",
      " '* The scale of the PLM and the delta-tuning method used can impact '\n",
      " 'performance and convergence.\\n'\n",
      " '* Combining different delta-tuning methods can improve performance, but '\n",
      " 'there is no optimal combination strategy.\\n'\n",
      " '\\n'\n",
      " 'The study highlights the importance of considering the structure and scale '\n",
      " 'of the model when evaluating the performance of delta-tuning methods. It '\n",
      " 'also emphasizes the potential benefits and limitations of combining '\n",
      " 'different delta-tuning methods.\\n'\n",
      " '\\n'\n",
      " 'The paper explores the properties of delta-tuning methods, including the '\n",
      " 'power of scale, task-level transferability, and combinatorial properties. '\n",
      " 'Two new delta-tuning methods, last-layer tuning and selective-module tuning, '\n",
      " 'are proposed and show promising results.\\n'\n",
      " '\\n'\n",
      " 'The studies in Nature Machine Intelligence explore various aspects of '\n",
      " 'machine learning models, including their performance, training methods, and '\n",
      " 'usage in research. Key themes include:\\n'\n",
      " '\\n'\n",
      " '* Performance evaluation and optimization of machine intelligence models '\n",
      " 'using different delta-tuning methods and fine-tuning techniques.\\n'\n",
      " '* Analysis of the time consumption and generalization gap of fine-tuning and '\n",
      " 'delta-tuning methods on various input lengths and datasets.\\n'\n",
      " '* Investigation of the usage of pre-trained language models (PLMs) in '\n",
      " 'research papers, finding that large PLMs are commonly used.\\n'\n",
      " '* Exploration of delta-tuning methods, which aim to reduce the number of '\n",
      " 'tunable parameters in transformer models while maintaining their '\n",
      " 'performance.\\n'\n",
      " '\\n'\n",
      " 'Overall, the studies highlight the potential of delta-tuning methods for '\n",
      " 'fine-tuning PLMs, emphasizing their efficiency and effectiveness in adapting '\n",
      " 'to specific tasks.')\n",
      "Generated 26 documents of ziegler.pdf.\n",
      "'Summary of ziegler.pdf:'\n",
      "('Here is the final, consolidated summary:\\n'\n",
      " '\\n'\n",
      " 'The study highlights the importance of fine-tuning language models using '\n",
      " 'human preferences and feedback to generate high-quality text. Fine-tuning '\n",
      " 'with a small amount of human data (5k-60k) and combining supervised and '\n",
      " 'reinforcement learning yields good results, particularly for summarization '\n",
      " 'tasks. The study emphasizes the need for careful evaluation and scoring of '\n",
      " 'generated text, and identifies challenges such as quality control, '\n",
      " 'overfitting, and ambiguous tasks. Overall, the study demonstrates the '\n",
      " 'effectiveness of fine-tuning language models with human preferences for '\n",
      " 'real-world applications.')\n",
      "Generated 26 documents of .ipynb_checkpoints.\n",
      "'Summary of .ipynb_checkpoints:'\n",
      "('Here is a final, consolidated summary of the main themes:\\n'\n",
      " '\\n'\n",
      " 'The summaries explore the fine-tuning of language models using human '\n",
      " 'preferences to improve their performance and safety in various tasks, '\n",
      " 'including text continuation, summarization, and sentiment analysis. The '\n",
      " 'approach involves training language models with human labels and optimizing '\n",
      " 'them to produce text that matches human preferences. The results show that '\n",
      " 'fine-tuning language models with human preferences can significantly improve '\n",
      " 'their performance, but may require careful consideration of the trade-offs '\n",
      " 'between extractive and abstractive summarization. Additionally, the '\n",
      " 'summaries touch on the importance of using high-quality labeled data, '\n",
      " 'regularization techniques, and online data collection to achieve the best '\n",
      " 'results.')\n",
      "CPU times: user 9.55 s, sys: 95.2 ms, total: 9.64 s\n",
      "Wall time: 1min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Iterate through PDF files in the articles directory\n",
    "    articles_dir = \"article/\"\n",
    "    \n",
    "    # Split docs to chunk\n",
    "    text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "        chunk_size=1000, chunk_overlap=0\n",
    "    )\n",
    "    \n",
    "    for filename in os.listdir(articles_dir):\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            file_path = os.path.join(articles_dir, filename)\n",
    "            loader = PyPDFLoader(file_path)\n",
    "            docs = loader.load()    \n",
    "            \n",
    "        split_docs = text_splitter.split_documents(docs)\n",
    "        print(f\"Generated {len(split_docs)} documents of {filename}.\")\n",
    "\n",
    "        # Do map reduce\n",
    "        map_reduce()\n",
    "        # Get final summarise text\n",
    "        result = map_reduce_chain.invoke(split_docs)\n",
    "        pprint.pp(f\"Summary of {filename}:\")\n",
    "        pprint.pp(result[\"output_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd3057b-5633-4ec3-849c-72f6962e3c50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
